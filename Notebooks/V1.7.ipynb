{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANDO BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas importantes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXIBIÇÃO DOS DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando a exibição do dataframe\n",
    "# A seguir estão configurações relacionadas à exibição de DataFrames no Pandas\n",
    "\n",
    "# Define o número máximo de colunas a serem exibidas sem truncamento\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Define se as colunas do DataFrame podem ser expandidas para ajustar a largura da tela\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Define a largura máxima de coluna para exibição sem truncamento\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Define o número máximo de linhas a serem exibidas ao imprimir o DataFrame\n",
    "pd.set_option('display.max_rows', 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEITURA DOS ARQUIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com caminhos locais distintos\n",
    "diretorios_locais = [\n",
    "    r'C:\\Users\\brand\\OneDrive\\Área de Trabalho\\Fraud_Detection_ML\\Data\\\\',\n",
    "    r'C:\\Users\\Giovanni Maia\\Desktop\\Dados\\\\'\n",
    "]\n",
    "\n",
    "diretorio_github= 'https://media.githubusercontent.com/media/jeanbrandao01/Fraud_Detection_ML/dev/Data/'\n",
    "\n",
    "def carregar_dataframes(diretorios_locais, diretorio_github):\n",
    "    for diretorio_local in diretorios_locais:\n",
    "        try:\n",
    "            # Tente carregar o DataFrame de fraudTest.csv a partir do diretório local\n",
    "            df_test = pd.read_csv(diretorio_local + 'fraudTest.csv')\n",
    "\n",
    "            # Tente carregar o DataFrame de fraudTrain.csv a partir do diretório local\n",
    "            df_train = pd.read_csv(diretorio_local + 'fraudTrain.csv')\n",
    "\n",
    "            # Se o carregamento for bem-sucedido, retorne os DataFrames\n",
    "            return df_test, df_train\n",
    "        except FileNotFoundError:\n",
    "            continue  # Continue para o próximo diretório local em caso de erro\n",
    "\n",
    "    # Se nenhum diretório local contiver os arquivos, carregue do GitHub\n",
    "    url_test = diretorio_github + 'fraudTest.csv'\n",
    "    url_train = diretorio_github + 'fraudTrain.csv'\n",
    "\n",
    "    df_test = pd.read_csv(url_test)\n",
    "    df_train = pd.read_csv(url_train)\n",
    "\n",
    "    return df_test, df_train\n",
    "\n",
    "df_test, df_train = carregar_dataframes(diretorios_locais,diretorio_github)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXIBIÇÃO DOS DATAFRAMES ORIGINAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe \"fraudTest.csv\"\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe \"fraudTrain.csv\"\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE DESCRITIVA: DATASET DE TREINO - FRAUDTRAIN.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas estatisticas do dataset\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as colunas existentes\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a contagem de valores da coluna \"merchant\"\n",
    "df_train.merchant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a contagem de valores da coluna \"is_fraud\"\n",
    "print(\"Contagem de valores da coluna is_fraud:\")\n",
    "print(\"-\"*39)\n",
    "print(df_train.is_fraud.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a extensão do dataset\n",
    "print(\"Extensão do dataset:\")\n",
    "print(\"-\"*23)\n",
    "print(df_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os nomes de cada coluna \n",
    "print(\"Colunas do dataset\")\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE EXPLORATÓRIA: DATASET DE TREINO - FRAUDTRAIN.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a proporção de fraudes\n",
    "fraud_proportion = df_train['is_fraud'].value_counts(normalize=True)\n",
    "\n",
    "# Criar um DataFrame para facilitar a criação do gráfico\n",
    "fraud_data = pd.DataFrame({'Classe de Fraude': fraud_proportion.index, 'Proporção': fraud_proportion.values})\n",
    "\n",
    "# Criar o gráfico de barras com o Plotly\n",
    "fig = px.bar(fraud_data, x='Classe de Fraude', y='Proporção', text='Proporção', title='Distribuição de Fraudes', labels={'Classe de Fraude': 'Classe de Fraude'})\n",
    "fig.update_traces(texttemplate='%{text:.2%}', textposition='outside')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrando a porcentagem de transações fraudulentas e não fraudulentas para cada categoria presente na coluna category \n",
    "round(pd.crosstab(index=df_train.category, columns=df_train.is_fraud, normalize='index')*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma tabela de contingência\n",
    "crosstab = pd.crosstab(index=df_train.category, columns=df_train.is_fraud, normalize='index') * 100\n",
    "\n",
    "# Reinicia o índice para facilitar o manuseio\n",
    "crosstab = crosstab.reset_index()\n",
    "\n",
    "# Cria um gráfico de barras empilhadas usando o Plotly Express\n",
    "fig = px.bar(crosstab, x='category', y=[0, 1], title=\"Gráfico de Barras Empilhadas da Tabela de Contingência (Percentual)\",\n",
    "             labels={0: \"Não Fraude\", 1: \"Fraude\"},\n",
    "             height=400)\n",
    "\n",
    "# Atualiza o layout para um gráfico de barras empilhadas\n",
    "fig.update_layout(barmode='stack')\n",
    "\n",
    "# Mostra o gráfico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa os dados por estado e calcula o número total de transações em cada estado\n",
    "total_transacoes_por_estado = df_train[\"state\"].value_counts()\n",
    "\n",
    "# Filtra os dados para transações fraudulentas\n",
    "dados_fraudulentos = df_train[df_train[\"is_fraud\"] == 1]\n",
    "\n",
    "# Agrupa os dados fraudulentos por estado e calcula o número de transações fraudulentas em cada estado\n",
    "transacoes_fraudulentas_por_estado = dados_fraudulentos[\"state\"].value_counts()\n",
    "\n",
    "# Calcula a taxa de fraude para cada estado (transações fraudulentas / total de transações)\n",
    "taxa_de_fraude = (transacoes_fraudulentas_por_estado / total_transacoes_por_estado).fillna(0)\n",
    "\n",
    "# Reinicia o índice e ordena os resultados por 'count' de forma descendente\n",
    "taxa_de_fraude.reset_index().sort_values(by='count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna as últimas 20 linhas (estados) dessa Series, representando os estados com o menor número de transações. \n",
    "total_transacoes_por_estado.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna o número de cidades únicas presentes na coluna cidade\n",
    "df_train.city.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa os dados por cidade e calcula o número total de transações em cada cidade\n",
    "total_transacoes_por_cidade = df_train[\"city\"].value_counts()\n",
    "\n",
    "# Filtra os dados para transações fraudulentas\n",
    "dados_fraudulentos = df_train[df_train[\"is_fraud\"] == 1]\n",
    "\n",
    "# Agrupa os dados fraudulentos por cidade e calcula o número de transações fraudulentas em cada cidade\n",
    "transacoes_fraudulentas_por_cidade = dados_fraudulentos[\"city\"].value_counts()\n",
    "\n",
    "# Calcula a taxa de fraude para cada cidade (transações fraudulentas / total de transações)\n",
    "taxa_de_fraude = (transacoes_fraudulentas_por_cidade / total_transacoes_por_cidade).fillna(0)\n",
    "\n",
    "# Seleciona as cidades com taxa de fraude igual a 1, reinicia o índice e ordena os resultados por 'count' de forma descendente\n",
    "taxa_de_fraude[taxa_de_fraude == 1].reset_index().sort_values(by='count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o estilo (opcional)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Cria um violin plot usando o Seaborn para valor da compra por classe\n",
    "plt.figure(figsize=(10, 6))  # Define o tamanho da figura (opcional)\n",
    "sns.violinplot(data=df_train.query('amt <= 200'), x='is_fraud', y='amt')\n",
    "# Define o título e rótulos\n",
    "plt.title('Violin Plot - Distribuição do Valor da Compra por Classe de Fraude')\n",
    "plt.xlabel('Classe de Fraude')\n",
    "plt.ylabel('Valor da Compra')\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o estilo (opcional)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Cria um boxplot usando o Seaborn para distruibuição do valor de compra\n",
    "plt.figure(figsize=(10, 6))  # Define o tamanho da figura (opcional)\n",
    "sns.boxplot(data=df_train.query('amt <= 200'), y='amt', color='skyblue')  # Adicionado cor para melhor visualização\n",
    "\n",
    "# Define o título e rótulos\n",
    "plt.title('Boxplot - Distribuição do Valor da Compra')\n",
    "plt.ylabel('Valor da Compra')\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o estilo (opcional)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Escolhe uma paleta de cores para as barras (cores mais claras)\n",
    "bar_palette = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "\n",
    "# Escolhe uma cor mais escura para a linha do KDE\n",
    "line_color = 'navy'\n",
    "\n",
    "# Cria um histograma com KDE usando o Seaborn para valor de compra\n",
    "plt.figure(figsize=(10, 6))  # Define o tamanho da figura (opcional)\n",
    "sns.histplot(data=df_train.query('amt <= 200'), x='amt', kde=True)\n",
    "sns.kdeplot(data=df_train.query('amt <= 200')['amt'], color=line_color, linewidth=2)\n",
    "\n",
    "# Define o título e rótulos\n",
    "plt.title('Histograma com KDE - Valor da Compra')\n",
    "plt.xlabel('Valor da Compra')\n",
    "plt.ylabel('Contagem')\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o estilo (opcional)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Cria um histograma com KDE usando o Seaborn para valores de compra acima de 2000\n",
    "plt.figure(figsize=(10, 6))  # Define o tamanho da figura (opcional)\n",
    "sns.histplot(data=df_train.query('amt > 2000'), x='amt', kde=True, color='red')  # Adiciona cor para melhor visualização\n",
    "\n",
    "# Define o título e rótulos\n",
    "plt.title('Histograma com KDE - Valor de Compra Acima de 2000')\n",
    "plt.xlabel('Valor de Compra')\n",
    "plt.ylabel('Contagem')\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as colunas numéricas\n",
    "numeric_columns = df_train.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calculando a matriz de correlação para colunas numéricas\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "# Criando uma figura maior\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Criando um mapa de calor de correlação com paleta de cores personalizada\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', center=0, cbar_kws={'label': 'Correlação'})\n",
    "plt.title('Mapa de Calor de Correlação')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise temporal\n",
    "\n",
    "# Convertendo a coluna 'trans_date_trans_time' para um objeto de data e hora\n",
    "df_train['trans_date_trans_time'] = pd.to_datetime(df_train['trans_date_trans_time'])\n",
    "\n",
    "# Extraindo características de data e hora\n",
    "df_train['ano'] = df_train['trans_date_trans_time'].dt.year\n",
    "df_train['mes'] = df_train['trans_date_trans_time'].dt.month\n",
    "df_train['dia_da_semana'] = df_train['trans_date_trans_time'].dt.day_name()\n",
    "df_train['hora'] = df_train['trans_date_trans_time'].dt.hour\n",
    "df_train['minuto'] = df_train['trans_date_trans_time'].dt.minute\n",
    "df_train['segundo'] = df_train['trans_date_trans_time'].dt.second\n",
    "\n",
    "# Filtrando fraudes\n",
    "frauds = df_train[df_train['is_fraud'] == 1]\n",
    "\n",
    "# Contando fraudes por mês\n",
    "frauds_by_month = frauds['mes'].value_counts().sort_index().reset_index()\n",
    "frauds_by_month.columns = ['Mês', 'Número de Fraudes']\n",
    "\n",
    "# Criando um gráfico de barras interativo com Plotly\n",
    "fig = px.bar(frauds_by_month, x='Mês', y='Número de Fraudes', title='Fraudes por Mês',\n",
    "             labels={'Mês': 'Mês', 'Número de Fraudes': 'Número de Fraudes'})\n",
    "\n",
    "# Adicionando números em cima das barras\n",
    "fig.update_traces(text=frauds_by_month['Número de Fraudes'], textposition='outside')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de ocorrências por categoria\n",
    "category_counts = df_train['category'].value_counts().reset_index()\n",
    "category_counts.columns = ['Categoria', 'Contagem']\n",
    "\n",
    "# Agrupando por categoria e calculando a proporção de fraudes\n",
    "fraud_proportion_by_category = df_train.groupby('category')['is_fraud'].mean().reset_index()\n",
    "fraud_proportion_by_category.columns = ['Categoria', 'Proporção de Fraudes']\n",
    "\n",
    "# Criando um gráfico de barras interativo com Plotly\n",
    "fig = px.bar(fraud_proportion_by_category, x='Categoria', y='Proporção de Fraudes', title='Proporção de Fraudes por Categoria',\n",
    "             labels={'Categoria': 'Categoria', 'Proporção de Fraudes': 'Proporção de Fraudes'})\n",
    "\n",
    "# Formatando os números com cinco casas decimais\n",
    "fraud_proportion_by_category['Proporção de Fraudes'] = fraud_proportion_by_category['Proporção de Fraudes'].round(5)\n",
    "\n",
    "# Adicionando os números formatados (com cinco casas decimais) em cima das barras\n",
    "fig.update_traces(text=fraud_proportion_by_category['Proporção de Fraudes'], textposition='outside')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['trans_date_trans_time'] = pd.to_datetime(df_train['trans_date_trans_time'])\n",
    "\n",
    "\n",
    "df_train.sort_values(by=['cc_num' ,'trans_date_trans_time'], ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "agrupado_cc_valor = df_train.groupby('cc_num')['amt']\n",
    "\n",
    "media_cartao = agrupado_cc_valor.transform('mean')\n",
    "desv_pad_cartao = agrupado_cc_valor.transform('std')\n",
    "\n",
    "df_train['media'] = media_cartao\n",
    "\n",
    "df_train['amt_score_z'] = (df_train['amt'] - media_cartao) / desv_pad_cartao\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.is_fraud == 0, 'amt_score_z'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select_dtypes(exclude='object').corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNÇÕES E CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione uma constante pequena antes de aplicar o log\n",
    "def calculate_woe(df, feature, target):\n",
    "    df = df[[feature, target]].copy()\n",
    "    df['n_total'] = 1\n",
    "    df = df.groupby([feature, target]).count().unstack().fillna(0)\n",
    "    df.columns = df.columns.droplevel()\n",
    "    df['n_event'] = df[1]\n",
    "    df['n_non_event'] = df[0]\n",
    "    df['n_total'] = df['n_event'] + df['n_non_event']\n",
    "    df['event_rate'] = df['n_event'] / df['n_event'].sum()\n",
    "    df['non_event_rate'] = df['n_non_event'] / df['n_non_event'].sum()\n",
    "    # Adicione uma constante pequena para evitar log(0)\n",
    "    df['woe'] = np.log((df['event_rate'] + 1e-9) / (df['non_event_rate'] + 1e-9))\n",
    "    woe_dict = df['woe'].to_dict()\n",
    "    return woe_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe do transformador WoE (Weight of Evidence)\n",
    "class WoETransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features):\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.woe_dict_ = {}\n",
    "        for column in self.categorical_features:\n",
    "            woe_values = calculate_woe(pd.DataFrame({column: X[column], 'target': y}), column, 'target')\n",
    "            self.woe_dict_[column] = woe_values\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for column, woe_values in self.woe_dict_.items():\n",
    "            X_transformed[column] = X_transformed[column].map(woe_values)\n",
    "        return X_transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREINAMENTO E AVALIAÇÃO DO MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 2: Função para treinar e prever para cada classificador\n",
    "def train_and_predict(classifier, X_train_transformed, y_train, X_test_transformed):\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train_transformed, y_train)\n",
    "    y_pred = pipe.predict(X_test_transformed)\n",
    "    return classifier.__class__.__name__, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 3: Função para avaliar métricas de desempenho\n",
    "def evaluate_metrics(y_true, y_pred, classifier_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)   \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    result = {\n",
    "        \"Classifier\": classifier_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "    }\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 4: Função principal que treina, avalia e prevê para cada classificador\n",
    "def train_evaluate_and_predict(classifier, X_train_transformed, y_train, X_test_transformed, y_test):\n",
    "    classifier_name, y_pred = train_and_predict(classifier, X_train_transformed, y_train, X_test_transformed)\n",
    "    metrics_result = evaluate_metrics(y_test, y_pred, classifier_name)\n",
    "    return classifier_name, metrics_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÉ PROCESSAMENTO E CRIAÇÃO DO PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 5: Pré-processamento e Treinamento do Modelo\n",
    "# Substitua 'df_train' pelos seus dados reais\n",
    "features = df_train[['amt', 'category', 'gender', 'city', 'state', 'zip', 'lat', 'long', 'unix_time', 'merch_lat', 'merch_long', 'ano', 'mes', 'dia_da_semana', 'hora', 'minuto', 'segundo']]\n",
    "labels = df_train['is_fraud']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Divisão dos dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de features numéricas contínuas e categóricas\n",
    "numericas_continuas = ['amt', 'zip', 'lat', 'long', 'unix_time', 'merch_lat', 'merch_long', 'ano', 'mes', 'hora', 'minuto', 'segundo']\n",
    "string_categoricas = ['category', 'gender', 'city', 'state', 'dia_da_semana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformador para features numéricas contínuas\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Transformador para features categóricas usando a classe WoETransformer\n",
    "categorical_transformer = WoETransformer(categorical_features=string_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de transformadores a serem aplicados a cada conjunto de features\n",
    "transformers = [\n",
    "    ('num_continuas', numeric_transformer, numericas_continuas),\n",
    "    ('str_categoricas', categorical_transformer, string_categoricas)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do ColumnTransformer integrado ao Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers,\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrando o ColumnTransformer ao Pipeline com Regressão Logística (substitua conforme necessário)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Treinamento do pré-processador nos dados de treino\n",
    "X_train_transformed = preprocessor.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Treinamento do modelo completo\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação do pré-processador nos dados de teste\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão nos dados de teste\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVALIAÇÃO EM PARALELO PARA TODOS OS CLASSIFICADORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 6: Avaliação em Paralelo para Todos os Classificadores\n",
    "# Lista de classificadores\n",
    "classifiers_list = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução em paralelo para todos os classificadores - Métricas\n",
    "metrics_results = Parallel(n_jobs=-1)(\n",
    "    delayed(train_evaluate_and_predict)(\n",
    "        classifier, X_train_transformed, y_train, X_test_transformed, y_test\n",
    "    ) for classifier in classifiers_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo classifier_names\n",
    "classifier_names = [classifier.__class__.__name__ for classifier in classifiers_list]\n",
    "\n",
    "# Organizando os resultados\n",
    "metrics_dict = {'Classifier': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-score': []}\n",
    "for result in metrics_results:\n",
    "    classifier_name, metrics_result = result\n",
    "    metrics_dict['Classifier'].append(classifier_name)\n",
    "    metrics_dict['Accuracy'].append(metrics_result['Accuracy'])\n",
    "    metrics_dict['Precision'].append(metrics_result['Precision'])\n",
    "    metrics_dict['Recall'].append(metrics_result['Recall'])\n",
    "    metrics_dict['F1-score'].append(metrics_result['F1-score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando DataFrame com os resultados\n",
    "metrics_df = pd.DataFrame(metrics_dict)\n",
    "# Exibindo o DataFrame\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor classificador\n",
    "\n",
    "# Especificar a métrica pela qual queremos classificar os modelos (por exemplo, F1-score)\n",
    "metric_to_maximize = 'F1-score'\n",
    "\n",
    "# Classificar o DataFrame pelo valor máximo da métrica\n",
    "sorted_df = metrics_df.sort_values(by=metric_to_maximize, ascending=False)\n",
    "\n",
    "# Exibir o classificador que obteve o melhor desempenho\n",
    "best_classifier = sorted_df.iloc[0]['Classifier']\n",
    "print(f\"O melhor classificador com base na métrica {metric_to_maximize} é: {best_classifier}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução em paralelo para todos os classificadores - Previsões\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_predict)(\n",
    "        classifier, X_train_transformed, y_train, X_test_transformed\n",
    "    ) for classifier in classifiers_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descompactando a lista de resultados\n",
    "classifier_names, predictions = zip(*results)\n",
    "\n",
    "# Criando um dicionário com os resultados\n",
    "data_dict = {\"is_fraud\": y_test}\n",
    "\n",
    "# Adicionando as previsões de cada classificador ao dicionário\n",
    "for classifier_name, prediction in zip(classifier_names, predictions):\n",
    "    data_dict[classifier_name] = prediction\n",
    "\n",
    "# Criando um DataFrame a partir do dicionário\n",
    "results_df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Exibindo o DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o pipeline com o classificador\n",
    "classifier_cv = RandomForestClassifier()\n",
    "\n",
    "# Criar o pipeline com o classificador\n",
    "pipe_cv = Pipeline(steps=[('classifier', classifier_cv)])\n",
    "\n",
    "# Definir a estratégia de validação cruzada (Stratified K-Fold)\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Definir as métricas desejadas\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Executar a validação cruzada e calcular as métricas\n",
    "cv_results = cross_validate(pipe_cv, X_train_transformed, y_train, cv=stratified_kfold, scoring=scoring_metrics)\n",
    "\n",
    "# Exibir os resultados\n",
    "for metric in scoring_metrics:\n",
    "    print(f\"{metric.capitalize()} médio na validação cruzada:\", cv_results[f'test_{metric}'].mean())\n",
    "    print(f\"Desvio padrão dos {metric.capitalize()} na validação cruzada:\", cv_results[f'test_{metric}'].std())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATRIZ DE CONFUSÃO PARA TODOS OS INDICADORES (Não usei a cv pra esse conjunto, apenas a validação normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de todas as colunas de previsão\n",
    "prediction_columns = [\n",
    "    'LogisticRegression',\n",
    "    'DecisionTreeClassifier',\n",
    "    'RandomForestClassifier',\n",
    "    'AdaBoostClassifier',\n",
    "    'GradientBoostingClassifier'\n",
    "]\n",
    "\n",
    "# Loop para criar matrizes de confusão interativas para cada classificador\n",
    "for classifier_column in prediction_columns:\n",
    "    # Criar a matriz de confusão\n",
    "    conf_matrix = confusion_matrix(results_df['is_fraud'], results_df[classifier_column])\n",
    "\n",
    "    # Configurações do heatmap\n",
    "    heatmap = ff.create_annotated_heatmap(\n",
    "        z=conf_matrix,\n",
    "        x=['Not Fraud', 'Fraud'],\n",
    "        y=['Not Fraud', 'Fraud'],\n",
    "        colorscale='Blues'\n",
    "    )\n",
    "\n",
    "    # Atualizar layout para adicionar rótulos\n",
    "    heatmap.update_layout(\n",
    "        xaxis=dict(title='Predicted'),\n",
    "        yaxis=dict(title='True'),\n",
    "        title=f'Confusion Matrix: is_fraud vs. {classifier_column}'\n",
    "    )\n",
    "\n",
    "    # Exibir o gráfico\n",
    "    heatmap.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APLICANDO A FUNÇÃO DE TREINO NO DE TESTE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
