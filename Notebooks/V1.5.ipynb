{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANDO BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXIBIÇÃO DOS DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando a exibição do dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEITURA DOS ARQUIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com caminhos locais distintos\n",
    "diretorios_locais = [\n",
    "    r'C:\\Users\\brand\\OneDrive\\Área de Trabalho\\Fraud_Detection_ML\\Data\\\\',\n",
    "    r'C:\\Users\\Giovanni Maia\\Desktop\\Dados\\\\'\n",
    "]\n",
    "\n",
    "diretorio_github= 'https://media.githubusercontent.com/media/jeanbrandao01/Fraud_Detection_ML/dev/Data/'\n",
    "\n",
    "def carregar_dataframes(diretorios_locais, diretorio_github):\n",
    "    for diretorio_local in diretorios_locais:\n",
    "        try:\n",
    "            # Tente carregar o DataFrame de fraudTest.csv a partir do diretório local\n",
    "            df_test = pd.read_csv(diretorio_local + 'fraudTest.csv')\n",
    "\n",
    "            # Tente carregar o DataFrame de fraudTrain.csv a partir do diretório local\n",
    "            df_train = pd.read_csv(diretorio_local + 'fraudTrain.csv')\n",
    "\n",
    "            # Se o carregamento for bem-sucedido, retorne os DataFrames\n",
    "            return df_test, df_train\n",
    "        except FileNotFoundError:\n",
    "            continue  # Continue para o próximo diretório local em caso de erro\n",
    "\n",
    "    # Se nenhum diretório local contiver os arquivos, carregue do GitHub\n",
    "    url_test = diretorio_github + 'fraudTest.csv'\n",
    "    url_train = diretorio_github + 'fraudTrain.csv'\n",
    "\n",
    "    df_test = pd.read_csv(url_test)\n",
    "    df_train = pd.read_csv(url_train)\n",
    "\n",
    "    return df_test, df_train\n",
    "\n",
    "df_test, df_train = carregar_dataframes(diretorios_locais,diretorio_github)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXIBIÇÃO DOS DATAFRAMES ORIGINAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe \"fraudTest.csv\"\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe \"fraudTrain.csv\"\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE DESCRITIVA: DATASET DE TREINO - FRAUDTRAIN.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas estatisticas do dataset\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as colunas existentes\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a contagem de valores da coluna \"merchant\"\n",
    "df_train.merchant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a contagem de valores da coluna \"is_fraud\"\n",
    "print(\"Contagem de valores da coluna is_fraud:\")\n",
    "print(\"-\"*39)\n",
    "print(df_train.is_fraud.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a extensão do dataset\n",
    "print(\"Extensão do dataset:\")\n",
    "print(\"-\"*23)\n",
    "print(df_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os nomes de cada coluna \n",
    "print(\"Colunas do dataset\")\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE EXPLORATÓRIA: DATASET DE TREINO - FRAUDTRAIN.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a proporção de fraudes\n",
    "fraud_proportion = df_train['is_fraud'].value_counts(normalize=True)\n",
    "\n",
    "# Criar um DataFrame para facilitar a criação do gráfico\n",
    "fraud_data = pd.DataFrame({'Classe de Fraude': fraud_proportion.index, 'Proporção': fraud_proportion.values})\n",
    "\n",
    "# Criar o gráfico de barras com o Plotly\n",
    "fig = px.bar(fraud_data, x='Classe de Fraude', y='Proporção', text='Proporção', title='Distribuição de Fraudes', labels={'Classe de Fraude': 'Classe de Fraude'})\n",
    "fig.update_traces(texttemplate='%{text:.2%}', textposition='outside')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrando a porcentagem de transações fraudulentas e não fraudulentas para cada categoria presente na coluna category \n",
    "round(pd.crosstab(index=df_train.category, columns=df_train.is_fraud, normalize='index')*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma tabela de contingência\n",
    "crosstab = pd.crosstab(index=df_train.category, columns=df_train.is_fraud, normalize='index') * 100\n",
    "\n",
    "# Reinicia o índice para facilitar o manuseio\n",
    "crosstab = crosstab.reset_index()\n",
    "\n",
    "# Cria um gráfico de barras empilhadas usando o Plotly Express\n",
    "fig = px.bar(crosstab, x='category', y=[0, 1], title=\"Gráfico de Barras Empilhadas da Tabela de Contingência (Percentual)\",\n",
    "             labels={0: \"Não Fraude\", 1: \"Fraude\"},\n",
    "             height=400)\n",
    "\n",
    "# Atualiza o layout para um gráfico de barras empilhadas\n",
    "fig.update_layout(barmode='stack')\n",
    "\n",
    "# Mostra o gráfico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa os dados por estado e calcula o número total de transações em cada estado\n",
    "total_transacoes_por_estado = df_train[\"state\"].value_counts()\n",
    "\n",
    "# Filtra os dados para transações fraudulentas\n",
    "dados_fraudulentos = df_train[df_train[\"is_fraud\"] == 1]\n",
    "\n",
    "# Agrupa os dados fraudulentos por estado e calcula o número de transações fraudulentas em cada estado\n",
    "transacoes_fraudulentas_por_estado = dados_fraudulentos[\"state\"].value_counts()\n",
    "\n",
    "# Calcula a taxa de fraude para cada estado (transações fraudulentas / total de transações)\n",
    "taxa_de_fraude = (transacoes_fraudulentas_por_estado / total_transacoes_por_estado).fillna(0)\n",
    "\n",
    "# Reinicia o índice e ordena os resultados por 'count' de forma descendente\n",
    "taxa_de_fraude.reset_index().sort_values(by='count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna as últimas 20 linhas (estados) dessa Series, representando os estados com o menor número de transações. \n",
    "total_transacoes_por_estado.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraudes por cidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna o número de cidades únicas presentes na coluna cidade\n",
    "df_train.city.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa os dados por cidade e calcula o número total de transações em cada cidade\n",
    "total_transacoes_por_cidade = df_train[\"city\"].value_counts()\n",
    "\n",
    "# Filtra os dados para transações fraudulentas\n",
    "dados_fraudulentos = df_train[df_train[\"is_fraud\"] == 1]\n",
    "\n",
    "# Agrupa os dados fraudulentos por cidade e calcula o número de transações fraudulentas em cada cidade\n",
    "transacoes_fraudulentas_por_cidade = dados_fraudulentos[\"city\"].value_counts()\n",
    "\n",
    "# Calcula a taxa de fraude para cada cidade (transações fraudulentas / total de transações)\n",
    "taxa_de_fraude = (transacoes_fraudulentas_por_cidade / total_transacoes_por_cidade).fillna(0)\n",
    "\n",
    "# Seleciona as cidades com taxa de fraude igual a 1, reinicia o índice e ordena os resultados por 'count' de forma descendente\n",
    "taxa_de_fraude[taxa_de_fraude == 1].reset_index().sort_values(by='count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o estilo (opcional)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Cria um violin plot usando o Seaborn para valor da compra por classe\n",
    "plt.figure(figsize=(10, 6))  # Define o tamanho da figura (opcional)\n",
    "sns.violinplot(data=df_train.query('amt <= 200'), x='is_fraud', y='amt')\n",
    "# Define o título e rótulos\n",
    "plt.title('Violin Plot - Distribuição do Valor da Compra por Classe de Fraude')\n",
    "plt.xlabel('Classe de Fraude')\n",
    "plt.ylabel('Valor da Compra')\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o estilo (opcional)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Cria um boxplot usando o Seaborn para distruibuição do valor de compra\n",
    "plt.figure(figsize=(10, 6))  # Define o tamanho da figura (opcional)\n",
    "sns.boxplot(data=df_train.query('amt <= 200'), y='amt', color='skyblue')  # Adicionado cor para melhor visualização\n",
    "\n",
    "# Define o título e rótulos\n",
    "plt.title('Boxplot - Distribuição do Valor da Compra')\n",
    "plt.ylabel('Valor da Compra')\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o estilo (opcional)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Escolhe uma paleta de cores para as barras (cores mais claras)\n",
    "bar_palette = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "\n",
    "# Escolhe uma cor mais escura para a linha do KDE\n",
    "line_color = 'navy'\n",
    "\n",
    "# Cria um histograma com KDE usando o Seaborn para valor de compra\n",
    "plt.figure(figsize=(10, 6))  # Define o tamanho da figura (opcional)\n",
    "sns.histplot(data=df_train.query('amt <= 200'), x='amt', kde=True)\n",
    "sns.kdeplot(data=df_train.query('amt <= 200')['amt'], color=line_color, linewidth=2)\n",
    "\n",
    "# Define o título e rótulos\n",
    "plt.title('Histograma com KDE - Valor da Compra')\n",
    "plt.xlabel('Valor da Compra')\n",
    "plt.ylabel('Contagem')\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o estilo (opcional)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Cria um histograma com KDE usando o Seaborn para valores de compra acima de 2000\n",
    "plt.figure(figsize=(10, 6))  # Define o tamanho da figura (opcional)\n",
    "sns.histplot(data=df_train.query('amt > 2000'), x='amt', kde=True, color='red')  # Adiciona cor para melhor visualização\n",
    "\n",
    "# Define o título e rótulos\n",
    "plt.title('Histograma com KDE - Valor de Compra Acima de 2000')\n",
    "plt.xlabel('Valor de Compra')\n",
    "plt.ylabel('Contagem')\n",
    "\n",
    "# Mostra o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as colunas numéricas\n",
    "numeric_columns = df_train.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calculando a matriz de correlação para colunas numéricas\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "# Criando uma figura maior\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Criando um mapa de calor de correlação com paleta de cores personalizada\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', center=0, cbar_kws={'label': 'Correlação'})\n",
    "plt.title('Mapa de Calor de Correlação')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise temporal\n",
    "\n",
    "# Convertendo a coluna 'trans_date_trans_time' para um objeto de data e hora\n",
    "df_train['trans_date_trans_time'] = pd.to_datetime(df_train['trans_date_trans_time'])\n",
    "\n",
    "# Extraindo características de data e hora\n",
    "df_train['ano'] = df_train['trans_date_trans_time'].dt.year\n",
    "df_train['mes'] = df_train['trans_date_trans_time'].dt.month\n",
    "df_train['dia_da_semana'] = df_train['trans_date_trans_time'].dt.day_name()\n",
    "df_train['hora'] = df_train['trans_date_trans_time'].dt.hour\n",
    "df_train['minuto'] = df_train['trans_date_trans_time'].dt.minute\n",
    "df_train['segundo'] = df_train['trans_date_trans_time'].dt.second\n",
    "\n",
    "# Filtrando fraudes\n",
    "frauds = df_train[df_train['is_fraud'] == 1]\n",
    "\n",
    "# Contando fraudes por mês\n",
    "frauds_by_month = frauds['mes'].value_counts().sort_index().reset_index()\n",
    "frauds_by_month.columns = ['Mês', 'Número de Fraudes']\n",
    "\n",
    "# Criando um gráfico de barras interativo com Plotly\n",
    "fig = px.bar(frauds_by_month, x='Mês', y='Número de Fraudes', title='Fraudes por Mês',\n",
    "             labels={'Mês': 'Mês', 'Número de Fraudes': 'Número de Fraudes'})\n",
    "\n",
    "# Adicionando números em cima das barras\n",
    "fig.update_traces(text=frauds_by_month['Número de Fraudes'], textposition='outside')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de ocorrências por categoria\n",
    "category_counts = df_train['category'].value_counts().reset_index()\n",
    "category_counts.columns = ['Categoria', 'Contagem']\n",
    "\n",
    "# Agrupando por categoria e calculando a proporção de fraudes\n",
    "fraud_proportion_by_category = df_train.groupby('category')['is_fraud'].mean().reset_index()\n",
    "fraud_proportion_by_category.columns = ['Categoria', 'Proporção de Fraudes']\n",
    "\n",
    "# Criando um gráfico de barras interativo com Plotly\n",
    "fig = px.bar(fraud_proportion_by_category, x='Categoria', y='Proporção de Fraudes', title='Proporção de Fraudes por Categoria',\n",
    "             labels={'Categoria': 'Categoria', 'Proporção de Fraudes': 'Proporção de Fraudes'})\n",
    "\n",
    "# Formatando os números com cinco casas decimais\n",
    "fraud_proportion_by_category['Proporção de Fraudes'] = fraud_proportion_by_category['Proporção de Fraudes'].round(5)\n",
    "\n",
    "# Adicionando os números formatados (com cinco casas decimais) em cima das barras\n",
    "fig.update_traces(text=fraud_proportion_by_category['Proporção de Fraudes'], textposition='outside')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados e divisão em treino/teste\n",
    "features = df_train[['amt', 'category', 'gender', 'city', 'state', 'zip', 'lat', 'long', 'unix_time', 'merch_lat', 'merch_long', 'ano', 'mes', 'dia_da_semana', 'hora', 'minuto', 'segundo']]\n",
    "labels = df_train['is_fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de transformadores para Pré-processamento\n",
    "numericas_continuas = ['amt', 'zip', 'lat', 'long', 'unix_time', 'merch_lat', 'merch_long', 'ano', 'mes', 'hora', 'minuto', 'segundo']\n",
    "string_categoricas = ['category', 'gender', 'city', 'state', 'dia_da_semana']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transformadores para variáveis numéricas contínuas\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Transformadores para variáveis categóricas\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "# Lista de tuplas indicando os transformadores a serem aplicados a cada conjunto de features\n",
    "transformers = [\n",
    "    ('num_continuas', numeric_transformer, numericas_continuas),\n",
    "    ('str_categoricas', categorical_transformer, string_categoricas)\n",
    "]\n",
    "\n",
    "# Criação do ColumnTransformer integrado ao Pipeline\n",
    "preprocessor = ColumnTransformer(transformers=transformers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREINAMENTO DO MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do pré-processador\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICADORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de classificadores\n",
    "classifiers_list = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinar, avaliar e prever para cada classificador\n",
    "def train_evaluate_and_predict(classifier, X_train_transformed, y_train, X_test_transformed, y_test):\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train_transformed, y_train)\n",
    "    y_pred = pipe.predict(X_test_transformed)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)   \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    result = {\n",
    "        \"Classifier\": classifier.__class__.__name__,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"Predictions\": y_pred\n",
    "    }\n",
    "\n",
    "    # Adicionar métricas sem as previsões\n",
    "    result_without_predictions = result.copy()\n",
    "    result_without_predictions.pop(\"Predictions\", None)\n",
    "\n",
    "    return result, result_without_predictions\n",
    "\n",
    "# Execução em paralelo para todos os classificadores\n",
    "results, results_without_predictions = zip(*Parallel(n_jobs=-1)(\n",
    "    delayed(train_evaluate_and_predict)(\n",
    "        classifier, X_train_transformed, y_train, X_test_transformed, y_test\n",
    "    ) for classifier in classifiers_list\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MÉTRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exiba os resultados sem as previsões\n",
    "print(\"\\nResults without Predictions:\")\n",
    "for result in results_without_predictions:\n",
    "    print(result)\n",
    "    print(\"---\")  # Adiciona uma linha separadora entre os resultados de diferentes classificadores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolha o classificador com a maior F1-score (média harmônica de precisão e recall)\n",
    "best_classifier_f1 = max(results_without_predictions, key=lambda x: (2 * x['Precision'] * x['Recall']) / (x['Precision'] + x['Recall']))\n",
    "\n",
    "# Exiba o resultado\n",
    "print(\"Melhor classificador (baseado no F1-score):\")\n",
    "print(best_classifier_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina pesos para as métricas (pode ajustar conforme necessário)\n",
    "weights = {\n",
    "    'Accuracy': 1,\n",
    "    'Precision': 1,\n",
    "    'Recall': 1,\n",
    "    'F1-score': 1\n",
    "}\n",
    "\n",
    "# Crie uma lista para armazenar as pontuações agregadas de cada classificador\n",
    "scores = []\n",
    "\n",
    "# Calcule as pontuações agregadas para cada classificador\n",
    "for result in results_without_predictions:\n",
    "    classifier_name = result['Classifier']\n",
    "    score = sum(result[metric] * weights[metric] for metric in weights) / sum(weights.values())\n",
    "    scores.append({'Classifier': classifier_name, 'Score': score})\n",
    "\n",
    "# Encontre o classificador com a pontuação mais alta\n",
    "best_classifier = max(scores, key=lambda x: x['Score'])\n",
    "\n",
    "# Exiba o resultado\n",
    "print(\"Melhor classificador (baseado na média ponderada das métricas):\")\n",
    "print(best_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Criar o pipeline com o classificador\n",
    "classifier_cv = RandomForestClassifier()\n",
    "\n",
    "# Criar o pipeline com o classificador\n",
    "pipe_cv = Pipeline(steps=[('classifier', classifier_cv)])\n",
    "\n",
    "# Definir a estratégia de validação cruzada (Stratified K-Fold)\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Definir as métricas desejadas\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Executar a validação cruzada e calcular as métricas\n",
    "cv_results = cross_validate(pipe_cv, X_train_transformed, y_train, cv=stratified_kfold, scoring=scoring_metrics)\n",
    "\n",
    "# Exibir os resultados\n",
    "for metric in scoring_metrics:\n",
    "    print(f\"{metric.capitalize()} médio na validação cruzada:\", cv_results[f'test_{metric}'].mean())\n",
    "    print(f\"Desvio padrão dos {metric.capitalize()} na validação cruzada:\", cv_results[f'test_{metric}'].std())\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATRIZ DE CONFUSÃO PARA TODOS OS INDICADORES (Não usei a cv pra esse conjunto, apenas a validação normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de todas as colunas de previsão\n",
    "prediction_columns = [\n",
    "    'LogisticRegression_Prediction',\n",
    "    'DecisionTreeClassifier_Prediction',\n",
    "    'RandomForestClassifier_Prediction',\n",
    "    'AdaBoostClassifier_Prediction',\n",
    "    'GradientBoostingClassifier_Prediction'\n",
    "]\n",
    "\n",
    "# Loop para criar matrizes de confusão interativas para cada classificador\n",
    "for classifier_column in prediction_columns:\n",
    "    # Criar a matriz de confusão\n",
    "    conf_matrix = confusion_matrix(df_predictions['is_fraud'], df_predictions[classifier_column])\n",
    "\n",
    "    # Configurações do heatmap\n",
    "    heatmap = ff.create_annotated_heatmap(\n",
    "        z=conf_matrix,\n",
    "        x=['Not Fraud', 'Fraud'],\n",
    "        y=['Not Fraud', 'Fraud'],\n",
    "        colorscale='Blues'\n",
    "    )\n",
    "\n",
    "    # Atualizar layout para adicionar rótulos\n",
    "    heatmap.update_layout(\n",
    "        xaxis=dict(title='Predicted'),\n",
    "        yaxis=dict(title='True'),\n",
    "        title=f'Confusion Matrix: is_fraud vs. {classifier_column}'\n",
    "    )\n",
    "\n",
    "    # Exibir o gráfico\n",
    "    heatmap.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA FRAME FINAL (AQUI É UM DF QUE TEM OS DADOS NORMAIS E OS DADOS DE PREDIÇÃO DOS 5 CLASSIFICADORES (Nome e predição)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do DataFrame final\n",
    "df_predictions = pd.DataFrame(df_train)  # Copiando o DataFrame original\n",
    "\n",
    "# Adição das previsões ao DataFrame final\n",
    "for result in results:\n",
    "    classifier_name = result[\"Classifier\"]\n",
    "    predictions = result[\"Predictions\"]\n",
    "    \n",
    "    # Ajuste para garantir que o número de previsões corresponda ao número de linhas no DataFrame original\n",
    "    if len(predictions) != len(df_predictions):\n",
    "        predictions = [0] * (len(df_predictions) - len(predictions)) + list(predictions)\n",
    "\n",
    "    df_predictions[f\"{classifier_name}_Prediction\"] = predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALVANDO O ARQUIVO JÁ TRATADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df_predictions.to_csv(\n",
    "    'V.Final.csv',  # Caminho e nome do arquivo\n",
    "    index=False,  # Não incluir índices no arquivo CSV\n",
    "    encoding='utf-8',  # Codificação do arquivo (pode ser 'utf-8', 'latin1', etc.)\n",
    "    sep=',',  # Delimitador de colunas (pode ser ',', ';', '\\t', etc.)\n",
    "    header=True  # Incluir cabeçalho no arquivo CSV\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
